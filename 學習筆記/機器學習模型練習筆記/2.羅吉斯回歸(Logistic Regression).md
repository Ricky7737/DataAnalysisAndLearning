# 羅吉斯回歸(Logistic Regression)
#### 羅吉斯回歸適合用於 "二元分類" 或 "多元分類"。
## 1.Logistic Regression(邏輯斯回歸) vs Linear Regression(線性回歸)
  * **1.Logistic Regression :** ```主要進行分類```。透過計算一個概率值，根據閾值（通常是0.5）進行分類預測。例如 : Kaggle Taitanic 預測乘客是否生還
    * **輸出類型 :** 輸出```介於 0 ~ 1 之間```的概率值，表示某一類別的可能性
    * **模型類型 :** 一樣為線性模型，但透過 ```Logistic函數（Sigmoid函數）``` 將線性組合轉換成概率值。

  * **2.Linear Regression(線性回歸)** 通常用於預測```連續數值資料```。透過建立一個線性模型透過特徵來預測。例如 : 房價預測、收入、溫度等等。
    * **輸出類型 :** 連續的實數，可以是 ```正數``` 或 ```負數```
    * **模型類型 :** 使用線性模型，通過特徵的加權線性組合來預測輸出
 
## 2. 羅吉斯迴歸 (Logistic Regression) 原理說明
### 線性回歸的公式 : p=E(Y=1|X)=β0+β1x1+...βnxn
  * 使用二元邏輯斯回歸時，```應變數(Y)```為二元分類變項，事件發生的機率 ```(Y=1)``` 可以以 p 表示，且 ```0 ≤ p ≤ 1```
  * 然而在 ```X(自變數)``` 特定數值下，平均值範圍可能 ```"大於1" 或 "小於 0"```
  * 因此將 ```條件機率P(Y=1|X)```做```羅吉斯轉換(logistic or logit transformation)```

### 邏輯斯回歸公式 : P(Y=1|X) = 1 / (1 + e^(-z))
  * P(Y=1|X) 表示在給定特徵X的情況下，預測Y等於1的概率
  * e 是自然對數的底數（約等於2.71828）
  * z 是一個線性組合，計算方式如下： z = b0 + b1X1 + b2X2 + ... + bn*Xn
  * b0 是截距（intercept）項，表示當所有特徵的值都為0時，Y等於1的概率
  * b1, b2, ..., bn 是特徵X1, X2, ..., Xn 的權重參數，用來衡量每個特徵對預測的影響








#### 參考資料
[1] https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html
[2] https://rpubs.com/jiankaiwang/lr
