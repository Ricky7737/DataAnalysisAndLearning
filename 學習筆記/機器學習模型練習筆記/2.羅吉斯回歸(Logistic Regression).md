# 羅吉斯回歸(Logistic Regression)
#### 羅吉斯回歸適合用於 "二元分類" 或 "多元分類"。
## 1.Logistic Regression(邏輯斯回歸) vs Linear Regression(線性回歸)
  * **1.Logistic Regression :** ```主要進行分類```。透過計算一個概率值，根據閾值（通常是0.5）進行分類預測。例如 : Kaggle Taitanic 預測乘客是否生還
    * **輸出類型 :** 輸出```介於 0 ~ 1 之間```的概率值，表示某一類別的可能性
    * **模型類型 :** 一樣為線性模型，但透過 ```Logistic函數（Sigmoid函數）``` 將線性組合轉換成概率值。

  * **2.Linear Regression(線性回歸)** 通常用於預測```連續數值資料```。透過建立一個線性模型透過特徵來預測。例如 : 房價預測、收入、溫度等等。
    * **輸出類型 :** 連續的實數，可以是 ```正數``` 或 ```負數```
    * **模型類型 :** 使用線性模型，通過特徵的加權線性組合來預測輸出
 
## 2. 羅吉斯迴歸 (Logistic Regression) 原理說明
### 線性回歸的公式 : p=E(Y=1|X)=β0+β1x1+...βnxn
  * 使用二元邏輯斯回歸時，```應變數(Y)```為二元分類變項，事件發生的機率 ```(Y=1)``` 可以以 p 表示，且 ```0 ≤ p ≤ 1```
  * 然而在 ```X(自變數)``` 特定數值下，平均值範圍可能 ```"大於1" 或 "小於 0"```
  * 因此將 ```條件機率P(Y=1|X)```做```羅吉斯轉換(logistic or logit transformation)```

### 邏輯斯回歸公式 : P(Y=1|X) = 1 / (1 + e^(-z))
  * P(Y=1|X) 表示在給定特徵X的情況下，預測Y等於1的概率
  * e 是自然對數的底數（約等於2.71828）
  * z 是一個線性組合，計算方式如下： ```z = b0 + b1X1 + b2X2 + ... + bn*Xn```
  * b0 是截距（intercept）項，表示當所有特徵的值都為0時，Y等於1的概率
  * ```b1, b2, ..., bn``` 是特徵```X1, X2, ..., Xn``` 的權重參數，用來衡量每個特徵對預測的影響

## 3.羅吉斯程式
```
### 載入套件
from sklearn.model_selection import train_test_split  #用來分割數據集
from sklearn.linear_model import LogisticRegression   #羅吉斯套件
# accuracy_score 用於計算模型準確度
# classification_report 生成包含分類模型性能指標報告，包含 精確度（precision）、召回率（recall）、F1分數（F1-score）和支持數（support）
# confusion_matrix（混淆矩陣）計算分類模型的混淆矩陣
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

## 創建範例數據
X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)
# n_samples=100 生成樣本數 100。 n_features=2 2個特徵 。n_informative=2 生成2個有價值的特徵
# n_redundant=0 生成的特徵中有多少個是冗餘的特徵
# random_state=42：這是一個種子值，用於確保生成的數據是可重現的


## 切割數據分成訓練集 與 測試集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# X 為特徵數據集。 y 為目標預測值，或是訓練目標
# test_size=0.2 設定測試數據切割整體資料的後面 2 成出來使用

## 創建 Logistic Regression模型
model_logistic = LogisticRegression()

## 訓練模型
model_logistic.fit(X_train, y_train)

## 預測數值
y_pred = model.predict(X_test)

## 計算模型精確度(這邊計算成百分比)
acc_Logistic = round(accuracy_score(y_test, y_pred)*100, 2)

## 顯示混淆矩陣
conf_matrix_Logistic = confusion_matrix(y_test, y_pred)

## 顯示分類報告
class_report = classification_report(y_test, y_pred)
```

#### 詳細 Logistic Regression 參數請參考 :
[1] https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html
[2] 中文版本(簡體中文) : https://scikit-learn.org.cn/view/378.html
[3] https://rpubs.com/jiankaiwang/lr
