# 3.支援向量機(Support Vector Machine, SVM)
#### SVM 為機器學習中可以用來針對 "小樣本"、"非線性資料"、"高維度" 與 "局部最小點" 等問題的演算法。SVM有以下的優缺點
  * **優點 :**
    * ```1. 高效的多為分類 :``` 高維度資料分類效果良好。例如 : 文本分類 或 圖像分類
    * ```2. 良好的泛化性能 :``` 可以處理較小的資料獲得良好泛化能力，提升新數據預測準確度
    * ```3. 非線性資料分類 :``` 可以用於非線性數據，功過核函數將數據映射到高維度空間
  * **缺點 :**
    * ```1. 對大數據集和高維數據的計算要求高 ：``` 維度過高容易造成運算上的負擔
    * ```2.對數據不平衡敏感 ：``` 特徵遠大於樣本的情況下容易造成過度擬和的問題
      
## 3.1 SVM 的原理

* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/bb72b2d7-0a4e-41e5-a723-b3c514e3c45e)

#### 1.原理為將 "低微度空間且線性" 的資料映射到 "高維度空間"，找到一個超平面將這些樣本分割

* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/1801f881-e5d9-47a8-aba6-ecc1b4c4f3dc)

#### 2. 而這個平面式的決定方式，可以讓 Margin 最大化，使當日後有新樣本來進行預測分類時成功機率更大。
* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/f312bf39-4c18-44a1-bf7c-2854d5246bcd)

* 以上圖片來源 : 參考資料[3]
#### 另外補充 : 
 * ```Margin（邊際) :``` 是指兩種分類之間的界線，SVM 的目的在於優化最大化的Margin，確保分類之間的界線有足夠的空間。這樣模型也比較好的性能，也降低錯誤分類的機率。




#### 參考資料來源:
* [1] https://blog.csdn.net/TeFuirnever/article/details/99646257
* [2] https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-4%E8%AC%9B-%E6%94%AF%E6%8F%B4%E5%90%91%E9%87%8F%E6%A9%9F-support-vector-machine-%E4%BB%8B%E7%B4%B9-9c6c6925856b
* [3] https://pyecontech.com/2020/03/24/svm/
