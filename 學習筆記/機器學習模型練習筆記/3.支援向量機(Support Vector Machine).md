# 3.支援向量機(Support Vector Machine, SVM)
#### SVM 為機器學習中可以用來針對 "小樣本"、"非線性資料"、"高維度" 與 "局部最小點" 等問題的演算法。SVM有以下的優缺點
  * **優點 :**
    * ```1. 高效的多為分類 :``` 高維度資料分類效果良好。例如 : 文本分類 或 圖像分類
    * ```2. 良好的泛化性能 :``` 可以處理較小的資料獲得良好泛化能力，提升新數據預測準確度
    * ```3. 非線性資料分類 :``` 可以用於非線性數據，功過核函數將數據映射到高維度空間
  * **缺點 :**
    * ```1. 對大數據集和高維數據的計算要求高 ：``` 維度過高容易造成運算上的負擔
    * ```2.對數據不平衡敏感 ：``` 特徵遠大於樣本的情況下容易造成過度擬和的問題
      
## 3.1 SVM 的原理

* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/bb72b2d7-0a4e-41e5-a723-b3c514e3c45e)

#### 1.原理為將 "低微度空間且線性" 的資料映射到 "高維度空間"，找到一個超平面將這些樣本分割

* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/1801f881-e5d9-47a8-aba6-ecc1b4c4f3dc)

#### 2. 而這個平面式的決定方式，可以讓 Margin 最大化，使當日後有新樣本來進行預測分類時成功機率更大。
* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/f312bf39-4c18-44a1-bf7c-2854d5246bcd)

* 以上圖片來源 : 參考資料[3]
#### 另外補充 : 
 * ```Margin（邊際) :``` 是指兩種分類之間的界線，SVM 的目的在於優化最大化的Margin，確保分類之間的界線有足夠的空間。這樣模型也比較好的性能，也降低錯誤分類的機率。

## 3.2 SVM 程式實作(以 Iris 鳶尾花資料作為範例)
#### (1) 載入套件、載入資料 與 分割資料。資料來源 : 參考資料 [5]
```
### 載入套件
from sklearn import svm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split

### 準備資料，使用 Sklearn 提供的鳶尾花資料
iris = datasets.load_iris()
X = iris.data
y = iris.target

### 分割資料
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
#### (2) 建立模型
```
### 建立模型
# 建立一個 svm 分類器
clf = svm.SVC(kernel='rbf', C=1, gamma='auto')
clf.fit(X_train, y_train)
```
* 參數說明
  * ```1. kernel = :``` 核函數(Kernel)。可以自行設定，包含線性、多項式、高斯、Sigmod等，可以針對資料特性做選擇。 程式中的 rbf 適合用來處理非線性資料
  * ```2. 參數C :``` 正則化參數，控制模型的 "複雜度" 與 "容錯能力"。設定越大表示容錯程度愈低，可能使分類過於精細產生過度擬和。反之太低可能使模型低度擬和。
  * ```3. 參數 gamma :``` 決定支援向量多寡，影響 "訓練" 與 "預測" 數度。此參數有兩個自動運算選擇，分別為 ```scale``` 與 ```auto```。

* 另外補充
  * ```svm.SVC (Support Vector Classification) : ``` 適合用來處理分類
  * ```svm.SVR (Support Vector Regression) :``` 適合用來處理連續型資料
  * ```svm.LinearSVC (Linear Support Vector Classification) :``` 也適合處理線性資料，但比起 SVC 更適合用來處理大樣本資料，但與 ```svm.SVC(kernel=’linear’)``` 不一樣。
  
#### (3) 預測
```
clf.predict(X_test)

out:array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,
       0, 2, 2, 2, 2, 2, 0, 0])
```

#### (4) 準度分析
```
### 準確度分析
print(clf.score(X_train, y_train))
print(clf.score(X_test, y_test))

out:
0.9916666666666667
1.0
```

#### 參考資料來源:
* [1] https://blog.csdn.net/TeFuirnever/article/details/99646257
* [2] https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-4%E8%AC%9B-%E6%94%AF%E6%8F%B4%E5%90%91%E9%87%8F%E6%A9%9F-support-vector-machine-%E4%BB%8B%E7%B4%B9-9c6c6925856b
* [3] https://pyecontech.com/2020/03/24/svm/
* [4] https://zhuanlan.zhihu.com/p/49331510
* [5] https://pyecontech.com/2020/04/11/python_svm/
