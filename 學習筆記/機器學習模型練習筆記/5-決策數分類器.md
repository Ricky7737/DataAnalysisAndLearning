# DecisionTreeClassifier(決策樹分類器)
## 1.決策樹介紹
### 1.1 決策樹基本介紹
  * 上一個練習到 ```SVM 分類器```，而 SVM 分類器用來預測資料是 A or B。
  * 而這裡的決策樹分類器，將資料透過輸入樹根後，根據 ```節點的條件``` 篩選出對應條件的資料，而最分類結果就是 ```樹葉```。

### 1.2決策數 優點 與 缺點
#### 優點
  * 1.決策樹模型```非常直觀```，相較於其他模型來說更容易解釋。
  * 2.適合用於```分類問題```。例如 : 圖像識別、文本分類、多類別分類等等
  * 3.也可以用於```回歸問題```。例如 : 股票、房價預測問題。
  * 4.```特徵重要性分析```，可以評估哪些特徵對於預測結果最有影響
  * 5.應用於```風險評估```等問題
#### 缺點
  * 1.



### 1.3決策樹如下
  * ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/c20ae8f5-b685-4ef6-9a0e-3f8370123752)
  * 圖片來源 : 參考資料[2]

### 1.2 決策樹結構






## 2.Sklearn DecisionTreeClassifier 程式實作
* 程式實作程式以 Sklearn 提供的 Iris 下去練習
### 1.載入套件
```
# 載入資料 與 pandas 套件
from sklearn.datasets import load_iris
import pandas as pd
# 繪製圖片工具
import matplotlib.pyplot as plt
import seaborn as sns
# 切割資料工具
from sklearn.model_selection import train_test_split
# 載入決策數分類器
from sklearn.tree import DecisionTreeClassifier
# 決策樹視覺化
from sklearn.tree import export_graphviz
import graphviz
```

### 2.載入資料 
```
# 從 Sklearn 載入鳶尾花資料集
iris = load_iris()

# 將 iris 資料轉換成 dataframe
#  columns: 將直行名稱設定為feature_names欄位，方便觀察
iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])

# 新增 taget 欄位
iris_df['target'] = iris['target']
```
* 資料如下
![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/d692350a-fa76-4dc9-9ba3-801de49df4a4)

#### 欄位資料特徵
  * Sepal length: 花萼長度 (cm)
  * Sepal width: 花萼寬度 (cm)
  * Petal length: 花瓣長度 (cm)
  * Petal width: 花瓣寬度 (cm)


### 3.繪製熱像關係矩陣圖
```
# 繪製關係矩陣熱像圖
correlation_matrix = iris_df.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("iris correlation matrix")
plt.show()
```
* 圖片如下
  ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/cdf89b46-be37-4dac-973f-5afbfd6cb790)

#### 由上面關係矩陣圖來看
  * ``` 0 代表 Setosa 山鳶尾```、```1 代表 versicolor 變色鳶尾``` 、 ```2 代表 virginica 維吉尼亞鳶尾```
  * 1.```Sepal width: 花萼寬度 (cm)``` 與 ```taget```呈現負相關系數，也就是花萼寬度越大越有可能是 ```Setosa 山鳶尾```
  * 2.其他特徵來說，都是與 ```target``` 呈現正相關

### 4.切割資料
```
# 切割資料
# 先刪除目標
X = iris_df.drop(['target'], axis=1)
y = iris_df['target']

# test_size=0.2 測試集佔 1 成
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)
```
### 5.建立 DecisionTreeClassifier 模型
```
# 使用決策樹
# max_depth 樹最多有三層
clf = DecisionTreeClassifier(max_depth=3)

# 擬合資料
clf.fit(X_train, y_train)
```

### 6.將決策樹視覺化
```
# 將決策數視覺化
# 繪製決策樹圖
# 獲取特徵名稱的列表
# Define class names as a list
g = export_graphviz(clf, out_file=None, feature_names=iris["feature_names"],
                    class_names=iris["target_names"],
                    filled=True, special_characters=True)                

# graph是把g畫成圖
graph = graphviz.Source(g)
graph
```
* 決策樹視覺化圖片
* ![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/2b32cd16-6606-4262-a325-269b2ba6cd32)

### 7.預測數據 與 計算分數
```
clf.predict(X_test)

out : array([0, 2, 0, 0, 0, 1, 1, 2, 0, 2, 1, 2, 2, 2, 2])

### 準確度分析
print(clf.score(X_train, y_train))
print(clf.score(X_test, y_test))

out :
0.9925925925925926
1.0
```


* code link : https://reurl.cc/edMXb7



#### 參考資料 :
* [1] 決策數分類器參數 : https://scikit-learn.org/0.15/modules/generated/sklearn.tree.DecisionTreeClassifier.html
* [2] 決策樹 : https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-ed102ee62dfa
