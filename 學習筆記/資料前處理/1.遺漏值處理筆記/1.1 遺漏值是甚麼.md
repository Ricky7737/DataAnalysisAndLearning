# 遺漏值是甚麼，還有如何處裡遺漏值
#### 而這個筆記參考 資料來源[1] 的教學文章，並選用 Kaggle Titanic 作為數據集練習
* Kaggle Titanic 資料連結 :  https://www.kaggle.com/competitions/titanic/data
## 1. 遺漏值介紹
### 1.1 遺漏值
#### 遺漏值在實際數據集中相當常見，而遺漏值會影響模型的 *性能* 或是 *準確度*。而遺漏值有不同形式的方式存在，所以我們必須選用合適的方法來處理。
* 遺漏值如下，會在資料中以 **NaN** 出現，代標這個格子缺乏一個數值
![image](https://github.com/Ricky7737/DataAnalysisAndLearning/assets/58324475/98eb04df-b4e8-4f74-8e7b-2340b8ec7d85)

### 1.2 遺漏值產生
  * 1.數據可能損壞或是不當維護缺失了數值
  * 2.可能某些原因人為遺漏的記錄的數值
  * 3.資料未被提供等因素
    
### 1.3 遺漏值種類 
#### 遺漏值有三種種類(MCAR、MNAR、MAR )
 * **1.MCAR(Missing Completely At Random, 隨機性的遺漏值)**
   ##### MCAR 數據缺失的概率對所有觀察值都是相同的，與數據其他變量無關。而這種遺漏值的產生可能是人為錯誤、系統或是設備故障。而這種遺漏值資料上來說分布比較不會影響資料的分布偏態。
   
 * **2.MAR(Missing At Random)**
   * 表示缺失數據的原因可以通過您擁有完整信息的變量來解釋，存在某種關係或模式。
   * 在MAR情況下，數據缺失的概率不同觀察值之間可能不同，但這種差異可以由其他已觀察到的變量來解釋
   * 缺失數據的出現取決於其他已知變量的值，但不能直接預測缺失值本身
   * 所以當這種遺漏值出現時，可能導致該資料出現偏差，所以必續特別處理確保分析不受到遺漏值的影響
   ##### 例如 : 今天做一個民意調查，然後性別為女性的受測者可能不願透漏年齡，就會變成遺漏值的形式出現
   
  * **3.MNAR(Missing Not At Random)**
    ##### MNAR 則表示遺漏值來自於未被觀察到的數據。例如在圖書館調查未歸還書籍的客人，可能無法接受該調查。或是說受訪者不願意在問卷中分享訊息

### 1.4 為甚麼要處理遺漏值
  * 1.許多機器學習演算法碰到遺漏值時可能會運算失敗。但部分方式有支持運算遺漏值的功能，例如 : K-nearest、Naive Bayes等
  * 2.如果未正確處理遺漏值，可能會導致最終訓練的模型 "預測" 或 "分類" 產生偏差
  * 3.如果忽略遺漏值，可能會使最後分析結果不夠精確，降低統計分析的結果可靠性，而無法有效解釋數據。

## 2. 遺漏值處理
### 2.1 知道遺漏值有多少個
#### 2.1.1 使用 Python 來檢查個欄位遺漏值
* 以 Titanic 的 train.csv 做為練習 :
    ```
    import pandas as pd
    row_TrainData = pd.read_csv(r'E:\DataLearn\4-Titanic\data\train.csv')
    
    #檢查個欄位遺漏值數字
    missing_TrainData = row_TrainData.isnull().sum()
    missing_TrainData
    
    out :
    assengerId      0
    Survived         0
    Pclass           0
    Name             0
    Sex              0
    Age            177
    SibSp            0
    Parch            0
    Ticket           0
    Fare             0
    Cabin          687
    Embarked         2
    dtype: int64
    ```
##### 從上面可以看到 Age、Cabin 與 Embarked 都有遺漏值

### 2.2 遺漏值常見處理方式
  * **2.2.1 刪除遺漏值 :** 包含刪除含有遺漏值的行或列。但可能會遺失部分數據
  * **2.2.2 填補遺漏值 :** 使用 **統計方式(例如:平均值(mean)、中位數(median)等)** 或是 **機器學習模型(例如:回歸或是K-nearest)** 。但這個可能會使模型有一小部分的偏差存在。
    #### 2.2.2.1 以資料集中的 Age 欄位來做練習
    * **1. 計算 平均數(mean):** 
    ```
    import pandas as pd
    # 使用平均數來填補遺漏值
    mean_age_value = row_TrainData['Age'].mean().round().astype(int)
    print('age欄位平均數 : ', mean_age_value)
    
    out :
    age欄位平均數 :  30
    ```
    * **2. 計算 中位數(mediam):** 
    ```
    median_age = row_TrainData['Age'].median()
    print('age欄位中位數 : ', median_age)

    out :
    age欄位中位數 :  28.0
    ```
    * **3. 計算 眾數(mode)**
    ```
    mode_age = row_TrainData['Age'].mode()
    # mode_age[0] 取出眾數列表中第一個眾數值
    print('age欄位最多的眾數 : ', mode_age[0])

    out :
    age欄位最多的眾數 :  24.0
    ```
    * **4.計算 標準差(std)**
    ```
    std_age = row_TrainData['Age'].std()
    print('age欄位標準差: ', std_age)

    out :
    age欄位標準差:  14.526497332334044
    ```
    #### 2.2.2.2 填補遺漏值
    * 可以使用 fillna() 語法如下
    ``` data['目標欄位'].fillna(要補入的數值, inplace=True)```
    * 舉例使用中位數來填補 age
    ```
    # 先備份一個要用來展示處理 age 遺漏值的數據集
    fillna_median_tain = row_TrainData.copy()
    # 填補遺漏值
    fillna_median_tain['Age'].fillna(median_age, inplace = True)
    fillna_median_tain['Age'].isnull().sum()

    out :
    0
    ```
    ##### 可以看到 age 欄位的 遺漏值被中位數填補後不在存在任何遺漏值

    #### 2.2.2.3 而這邊另外補充一個方法 method = ffill
    * method = ffill 為使用前一個數值來填補遺漏值本身，語法如下
    ```
    data = {'A': [1, 2, None, 4, None, 6, 7],
            'B': [None, 22, 23, None, 25, 26, None]}
    df = pd.DataFrame(data)
    df

    out:
       A	  B
    0 1.0	NaN
    1 2.0	22.0
    2 NaN	23.0
    3 4.0	NaN
    4 NaN	25.0
    5 6.0	26.0
    6 7.0	NaN
    
    ----------------------------------------------------------
    # 填充遺漏值
    df_filled = df.fillna(method='ffill')
    print(df_filled)

    out:
       A    B
    0 1.0  NaN
    1 2.0  22.0
    2 2.0  23.0
    3 4.0  23.0
    4 4.0  25.0
    5 6.0  26.0
    6 7.0  26.0
    ```
    
  * **2.2.3 透過 interpolate  來插入數值**
    #### 其中方式有 : polynomial(多項式)、linear(線性) 或 quadratic(二次插值) 等方式。而默認的方法是 linear(線性插入)。程式如下:
    ```
    df_fillnull_Linear = df.interpolate()
    df_fillnull_Linear

    out :
      A	  B
    0 1.0	NaN
    1 2.0	22.0
    2 3.0	23.0
    3 4.0	24.0
    4 5.0	25.0
    5 6.0	26.0
    6 7.0	26.0
    ```
  * **2.2.4 對分類特徵添補遺漏值 :** 當特徵中屬於分類時，可以適當填補以處理遺漏
    #### 2.2.4.1 使用 sklearn 的 SimpleImputer
      ##### SimpleInputer 為 Sklearn 提供用來補足數據遺漏值的方式。透過 ```strategy='strategy_name'``` 選擇填補方式。方式如下 :
        ##### 1. 針對數值型資料
        * **mean :** 使用平均值填充
        * **median :** 使用中位數填充
        * **constant :** 使用指定的常數填充
        ###### 2. 針對類別型資料
        * **most_frequent :** 使用常見的類別來填充資料 
    ```
    # 首先先創造一個帶有空值的資料
    X = pd.DataFrame({'shape':['Apple', 'banana', 'banna', 'orange', np.nan]})
    X

    out :
         shape
     0	Apple
     1	banana
     2	banna
     3	orange
     4 NaN
    ----------------------------------------------------------
    # 使用 simpleInputer
    from sklearn.impute import SimpleImputer
    # strategy='most_frequent' 設定填補方式
    imputer = SimpleImputer(strategy='most_frequent')
    # 填充遺漏值
    imputer.fit_transform(X)
    ```
    #### 2.2.5 使用多個變數的方法填充遺漏值 : 例如 KNNImputer 或是 IterativeImputer
    ##### 回到 titanic 數據集為例。假設 Age 與 Fare 存在關聯，票價低的人可能較年輕，而票價高的人也更年輕。因此對於低票價的乘客以較低的年齡填充，而高票價反之。這邊採用多變量方式考慮多個特徵。
    
    * **2.2.5.1 使用 IterativeImputer**
      ##### 這是一種多變量的填補遺漏值方式，可以考慮多個特徵估算遺漏值，在補捉變量之間的關係非常強大。以下為程式碼與參數解說
      * 參數可以參考這裡 : https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html
      ```
      ## 載入套件
      # 啟用 IterativeImputer
      from sklearn.experimental import enable_iterative_imputer
      # 導入 IterativeImputer，用以填充遺漏值
      from sklearn.impute import IterativeImputer
      
      ### 參數補充
      imputer = IterativeImputer(max_iter=10, random_state=0)
      # max_iter : 設定填充迭代最大次數。可以根據數據集大小調整
      # random_state : 用於確保結果可重複性，使用相同隨機種子進行運算
      
      ----------------------------------------------------------
      ## 生成一個資料集，用來展示填補遺漏值
      IterativeImputerData = row_TrainData.copy()
      cols = ['SibSp', 'Fare', 'Age']
      X1data = KnnImputerData[cols]
      X1data.head()

      out:
         SibSp	  Fare	  Age
      0	 1	    7.2500	  22.0
      1	 1	    71.2833 	38.0
      2	 0	    7.9250	  26.0
      3	 1	    53.1000 	35.0
      4	 0	    8.0500	  35.0
      
      ----------------------------------------------------------
      ## 填充遺漏值
      # 創建一個 IterativeImputer
      impute_it = IterativeImputer()
      # 將數據擬合，然後透過套件內部回歸模型來估算遺漏值，進行填充
      impute_it.fit_transform(X1data)

      out:
      array([[ 1.  ,  7.25     , 22.        ],
            [ 1.   , 71.2833   , 38.        ],
            [ 0.   ,  7.925    , 26.        ],
            ...,
            [ 1.   , 23.45     , 26.82938751],
            [ 0.   , 30.       , 26.        ],
            [ 0.   ,  7.75     , 32.        ]])
      ----------------------------------------------------------
      ```
      ##### 這個範例透過 IterativeImputer 先從 'Age'不帶有遺漏值的行來篩選出應對的 'Sib sp' 與 'Fare'作為訓練特徵，以 'Age' 作為目標。透過前面 2 個特徵訓練練模型對 'Age' 做預測後，進行填補遺漏值
      
      
    * **2.2.5.2 使用 KNNImputer**
      ##### KNNImputer 使用鄰近的數值方式來填補遺漏值。程式範例如下
      * 參數可以參考這裡 : https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html
      ```
      ## 建立一個 KNNImputer用資料集
      KnnImputerData = row_TrainData.copy()
      cols = ['SibSp', 'Fare', 'Age']
      X2data = KnnImputerData[cols]
      X2data.head()

      out:
         SibSp	 Fare	    Age
      0	 1	     7.2500	  22.0
      1	 1	     71.2833 	38.0
      2	 0	     7.9250	  26.0
      3	 1	     53.1000 	35.0
      4	 0	     8.0500	  35.0

      ----------------------------------------------------------
      ## 載入 KNNImputer 套件
      from sklearn.impute import KNNImputer
      ## 填充資料
      # n_neighbors=2
      imputer_knn = KNNImputer(n_neighbors=2)
      imputer_knn.fit_transform(X2data)

      out:
      array([[ 1.   ,  7.25    , 22.    ],
            [ 1.    , 71.2833  , 38.    ],
            [ 0.    ,  7.925   , 26.    ],
            ...,
            [ 1.    , 23.45    , 29.    ],
            [ 0.    , 30.      , 26.    ],
            [ 0.    ,  7.75    , 32.    ]])
      ```
      ##### 在上面的範例中， n_neighbors=2 ，因此會去找尋最相似的 2 行觀察值來衡量要填充甚麼數值。

## 3. 將遺漏值作為一個特徵處理
#### 在某些情況下，當您填充遺漏值時，可以保留遺漏值，並將其作為一個額外的特徵，因為有時候遺漏值的也跟其他變數特徵存在這個關係。這時候可以添加一個遺漏值指示器(missing indicator) 為遺漏值做編碼放置在數據集最後一欄，他會指出那些數據點為遺漏值。
#### * 現在舉一個例子，假設預測一個疾病的存在，遺漏的年齡資料為良好的疾病預測因子，因為我們沒有貧窮人口的紀錄。而年齡是在貧窮人口資料中遺漏，所以遺漏的年齡就可以做為特徵之一來預測疾病。程式範例如下:
```
## 創建一個 age 資料
age = pd.DataFrame({'Age':[20, 30, 10, np.nan, 10]})
age

out:
   Age
0	20.0
1	30.0
2	10.0
3	NaN
4	10.0
----------------------------------------------------------
# 開始填補遺漏值
from sklearn.impute import SimpleImputer
# impute the mean
imputer = SimpleImputer()
imputer.fit_transform(age)

out:
array([[20. ],
       [30. ],
       [10. ],
       [17.5],
       [10. ]])
----------------------------------------------------------
## add_indicator=True 添加一個遺漏值指示器
imputer = SimpleImputer(add_indicator=True)
imputer.fit_transform(age)

out:
array([[20. ,  0. ],
       [30. ,  0. ],
       [10. ,  0. ],
       [17.5,  1. ],
       [10. ,  0. ]])
```
##### 可以看到 17.5 那邊先前為遺漏值 NaN，所以在添加遺漏值後變成 1

## 結論
處理遺漏值的方式會影響到最終訓練模型的準確度，因此選用合適的填補遺漏值方式非常重要。每種方式都有其優點與缺點。

#### 參考資料來源 :
* [1] https://www.analyticsvidhya.com/blog/2021/10/handling-missing-value/















