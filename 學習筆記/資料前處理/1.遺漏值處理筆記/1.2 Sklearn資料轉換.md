# 1.2 使用 Sklearn 資料轉換
* sklearn 中的 ```sklearn.preprocessing``` 提供多種**轉換器**，轉換器可以幫助數據進行特徵縮放，或是處理離群值。

## 1.2.1 Standardization, or mean removal and variance scaling
#### 標準化(Standardization)** 用於改變數據特徵的尺度，為常見的處理過程之一，因為正常的數據特徵資料分布不太可能是正態分布，因此我們會需要 "StanderScaler"。有兩中步驟
   * **1. 均值去除(Mean Removal) :** 目的讓特徵平均值都變成零，用意在於消除特徵之間的平移差異，使模型更容易訓練與理解特徵。
   * **2. 方差縮放（Variance Scaling）:** 可以確保每個特徵的變異都相對一致。將每個特徵值除以標準差來實現，會將所有特徵的變異性都變成 1，使模型訓練過程中不會特別關注某一個特徵。因為某些機器學習演算法對於特徵尺度分布非常敏感，這個可能導致模型性能下降，無法訓練出可靠的模型。
#### 程式如下 :
```
# 載入套件
from sklearn import preprocessing #數據預處理工具
import numpy as np

# 建立一個數據集
X_train = np.array([[1., -1., 2.], 
                    [2., 0., 0.], 
                    [0., 1., -1.]])

# 創建一個 StanderScaler 使用 fit()對 X_train 進行擬合
# 計算特徵的平均值 與 標準差
scaler = preprocessing.StandardScaler().fit(X_train)

#將擬合過的數據進行標準化轉換
X_scaled = scaler.transform(X_train)

out :
scaler.mean_
>>> array([1., 0., 0.33333333])
-----------------------------------------------------------
scaler.scale_
>>> array([0.81649658, 0.81649658, 1.24721913])
-----------------------------------------------------------
X_scaled
>>> array([[ 0.    , -1.22474487,  1.33630621],
       [ 1.22474487,  0.        , -0.26726124],
       [-1.22474487,  1.22474487, -1.06904497]])
-----------------------------------------------------------
X_scaled.mean(axis=0)
>>> array([0., 0., 0.])
-----------------------------------------------------------
X_scaled.std(axis=0)
array([1., 1., 1.])
```
## 1.2.1.1 Transformer API(轉換器 API)
#### sklearn 中用來數據執行轉換的估算器(estimator)，使數據處理更一致化
* **1.估算器(estimator) :** 用於數據轉換，有 **fit 與 transform**。"fit"用於擬合估算器需要運算的數據，"transform" 用於對數據執行實際的轉換。
* **2.一致的API :** 這是scikit-learn 這是scikit-learn，用於環城隊數據進行轉換。
* **3.預處理 :** 估算器通常用於數據預處理，例如標準化、特徵縮放、特徵選擇、特徵提取等。它們能夠幫助準備數據，使其更適合用於機器學習模型的訓練和預測
* **4. Pipeline中的應用** 在pipeline 的早期步驟中使用，確保數據在訓練和測試數據上應用相同轉換。
#### 程式碼如下 :
```
# 用於生成或載入樣本數據集的函數，使用了 make_classification 函數生成一個隨機的二元分類數據集
# 線性模型，使用了 LogisticRegression 類別來建立二元分類模型
# 提供了模型選擇和評估的工具，包括數據集分割和交叉驗證等。train_test_split 函數將數據集分為訓練集和測試集
# Pipeline 類別，將多個估算器（estimator）串聯在一起，使用 make_pipeline 函數創建了一個Pipeline，包含了標準化 (StandardScaler) 和Logistic Regression模型
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import  StandardScaler

# 生成一個隨機的二元分類數據集
X, y = make_classification(random_state=42)
# 分割數據成 "訓練集" 與 "測試集"
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
# 建立一個"datapipeline，第一個步驟是標準化，再來建立二元分類"
pipe = make_pipeline(StandardScaler(), LogisticRegression())
# 使用fit 先將訓練數據集標準化後再訓練，然後使用"y_train"作為目標
pipe.fit(X_train, y_train)

out:
>>> Pipeline(steps=[('standardscaler', StandardScaler()),
                ('logisticregression', LogisticRegression())])
-----------------------------------------------------------
# 評估模型訓練的準確度
pipe.score(X_test, y_test)
out:
>>> 0.96
# 代表這個二元模型準確度有 96%，非常不錯
```
* ```with_mean = False``` : 在標準化過程中不會減去平均值，意味著數據標準化後會"保留原始的平均值"
* ```with_std = False``` : 標準化後不會將每個特徵除標準差，也不會進行特徵縮放，意味著標準化後可以保留數據的"原始特徵尺度"

## 1.2.1.2 Scaling features to a range 
#### 將特徵縮放到最大與最小值之間，通常是 [0 ~ 1] 之間，或是使用每個特徵的最大或最小值縮放。可以透過 "MinMaxScaler" 或 "MaxAbsScaler"
* 有時候因為特徵標準差非常小，標準化後可能使值分布過於接近，這種方式可以保留特徵值在一個較大的範圍內，從而降低特徵過度敏感
* 保留稀疏數據，標準化可能導致 "零值" 變為 "非零值"。而這種方式更加適合處理稀疏的數據。
#### 程式碼如下 :
```
# 生成一個簡單的小型矩陣
X_train = np.array([[ 1., -1.,  2.],
                    [ 2.,  0.,  0.],
                    [ 0.,  1., -1.]])

# 使用"MinMaxScaler()" 將矩陣數值縮放到在 [0~1] 之間
min_max_scaler = preprocessing.MinMaxScaler()
X_train_minmax = min_max_scaler.fit_transform(X_train)
X_train_minmax

out:
>>> array([[0.5  , 0.    , 1.        ],
           [1.   , 0.5   , 0.33333333],
           [0.   , 1.    , 0.        ]])
-----------------------------------------------------------
# 來測試新的數據集
X_test = np.array([[-3., -1., 4.]])
X_test_minmax = min_max_scaler.transform(X_test)
X_test_minmax

out:
>>> array([[-1.5  ,  0. ,1.66666667]])
-----------------------------------------------------------
min_max_scaler.scale_

out:
>>> array([0.5  , 0.5  , 0.33333333])
-----------------------------------------------------------
min_max_scaler.min_
>>> array([0.5  , 0.5  , 0.33333333])
```

### 參考資料 : scikit Learn 網站
  * 連結:https://scikit-learn.org/stable/modules/preprocessing.html
